{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NTnfapvoRoUt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import Compose\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgAvOz_FSOVM",
        "outputId": "f1b4532c-ecce-47ec-e4c5-afa55e1c01ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/MyDrive/research_project'\n",
        "os.chdir(project_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jANkppypST2U"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/research_project'\n",
        "data_path = '/content/drive/MyDrive/research_project/all_selected'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9XMDMV6JSWMC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTm6g1XGSz8R"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tkKh0B98Shev"
      },
      "outputs": [],
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        # Shared MLP\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels // reduction, channels, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x_concat = torch.cat([avg_out, max_out], dim=1)\n",
        "        return self.sigmoid(self.conv(x_concat))\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel_attention = ChannelAttention(channels, reduction)\n",
        "        self.spatial_attention = SpatialAttention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * self.channel_attention(x)\n",
        "        x = x * self.spatial_attention(x)\n",
        "        return x\n",
        "\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        # Load pretrained ResNet50 with proper weights specification\n",
        "        weights = models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "        self.resnet = models.resnet50(weights=weights)\n",
        "        # Remove the final fully connected layer\n",
        "        self.features = nn.Sequential(*list(self.resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "class CBAMClassifier(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(CBAMClassifier, self).__init__()\n",
        "        self.feature_extractor = ResNetFeatureExtractor(pretrained)\n",
        "        self.cbam = CBAM(channels=2048)  # ResNet50 has 2048 channels in final layer\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "        # Initialize the weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Handle grayscale input\n",
        "        if x.size(1) == 1:\n",
        "            x = x.repeat(1, 3, 1, 1)\n",
        "\n",
        "        # Extract features\n",
        "        x = self.feature_extractor(x)\n",
        "\n",
        "        # Apply CBAM\n",
        "        x = self.cbam(x)\n",
        "\n",
        "        # Global pooling and classification\n",
        "        x = self.global_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xZLqF_dyS_NT"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        #labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Open the image\n",
        "        image = Image.open(file_path).convert('L')  # Convert to grayscale\n",
        "\n",
        "        # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To847pnkTFpk",
        "outputId": "e29fbb71-e425-46ee-d4da-e23192522a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file path: /content/drive/MyDrive/research_project/all_selected/Selected_Frames_3/301_18_1_9_1_stand/24372.png\n",
            "label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "file_paths = []\n",
        "labels = []\n",
        "correct_labels = []\n",
        "# Iterate through each folder (e.g., 'Selected_Frames_1-1')\n",
        "for folder in os.listdir(data_path):\n",
        "    folder_path = os.path.join(data_path, folder)\n",
        "\n",
        "    # Only consider directories that contain image subdirectories\n",
        "    if os.path.isdir(folder_path):\n",
        "        for subfolder in os.listdir(folder_path):\n",
        "            subfolder_path = os.path.join(folder_path, subfolder)\n",
        "\n",
        "            # Only consider directories that contain .png files\n",
        "            if os.path.isdir(subfolder_path):\n",
        "                subfolder_parts = subfolder.split('_')\n",
        "\n",
        "                # Ensure that the subfolder name has at least 5 parts (to extract correct label)\n",
        "                if len(subfolder_parts) >= 5:\n",
        "                    correct_label = int(subfolder_parts[4])  # Extract CorrectLabel from the 5th part\n",
        "                    correct_labels.append(correct_label)\n",
        "\n",
        "                    for file_name in os.listdir(subfolder_path):\n",
        "                        if file_name.endswith('.png'):  # Only consider .png files\n",
        "                            file_path = os.path.join(subfolder_path, file_name)\n",
        "                            file_paths.append(file_path)\n",
        "                            labels.append(correct_label - 1)  # Correct label is either 1 or 2, so subtract 1\n",
        "\n",
        "# Print the first file path and label\n",
        "print(f\"file path: {file_paths[0]}\")\n",
        "print(f\"label: {labels[:100]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOcJDehRkZFx",
        "outputId": "553065d8-da04-41d7-ac42-cb5705f2088f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique labels: 3\n",
            "Unique labels: [1 2 3]\n"
          ]
        }
      ],
      "source": [
        "unique_labels = np.unique(correct_labels)\n",
        "print(f\"Number of unique labels: {len(unique_labels)}\")\n",
        "print(f\"Unique labels: {unique_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eE7_O1AT7jm",
        "outputId": "2749eed7-65ba-4d88-cf15-f914a1fb6720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25890\n",
            "25890\n"
          ]
        }
      ],
      "source": [
        "print(len(file_paths))\n",
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haBu6_PbBRq3"
      },
      "source": [
        "ignoring where correct label is 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqzm_QbXktJ-",
        "outputId": "52a80ef2-e2a4-40f2-817c-ada11a77862f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/research_project/all_selected/Selected_Frames_2-5/204_18_8_14_3_chair/20395.png\n"
          ]
        }
      ],
      "source": [
        "# prompt: print only the last part of the file path where label is 2\n",
        "\n",
        "import os\n",
        "\n",
        "# Assuming 'file_paths' and 'labels' are defined as in your provided code.\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "    if label == 2:\n",
        "        print((file_paths[i]))\n",
        "        break # Assuming you only need the first instance where label is 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UI09OrO0l-BS"
      },
      "outputs": [],
      "source": [
        "# prompt: remove from file_paths and the corresponding labels wherever the labels==2\n",
        "\n",
        "# Assuming 'file_paths' and 'labels' are defined as in your provided code.\n",
        "\n",
        "new_file_paths = []\n",
        "new_labels = []\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "    if label != 2:\n",
        "        new_file_paths.append(file_paths[i])\n",
        "        new_labels.append(label)\n",
        "\n",
        "file_paths = new_file_paths\n",
        "labels = new_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpOu2O7xmMYO",
        "outputId": "f93e8c66-d3a1-4269-f15a-778247ecaba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique labels: 2\n",
            "Unique labels: [0 1]\n"
          ]
        }
      ],
      "source": [
        "unique_labels = np.unique(labels)\n",
        "print(f\"Number of unique labels: {len(unique_labels)}\")\n",
        "print(f\"Unique labels: {unique_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Y11IXdmSx5",
        "outputId": "e3b31351-79bf-4688-bfca-37c52384b301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25770\n",
            "25770\n"
          ]
        }
      ],
      "source": [
        "print(len(file_paths))\n",
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtRLNea9jrKe",
        "outputId": "101af30b-6305-4238-d0b5-9270f67dae38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [file_path, label]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# prompt: print where label is 2\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'labels' is defined as in your provided code\n",
        "df = pd.DataFrame({'file_path': file_paths, 'label': labels})\n",
        "\n",
        "# Print rows where label is 2\n",
        "print(df[df['label'] == 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9S5PkHwLT_9H"
      },
      "outputs": [],
      "source": [
        "#60 training\n",
        "train_files, temp_files, train_labels, temp_labels = train_test_split(file_paths, labels, test_size=0.4, random_state=42)\n",
        "#splitting the 40 into 20 and 20\n",
        "val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4OxwbVhUMaN",
        "outputId": "01a4391e-cb6c-4700-b8cc-0f0ffafdd82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15462\n",
            "15462\n",
            "5154\n",
            "5154\n"
          ]
        }
      ],
      "source": [
        "print(len(train_files))\n",
        "print(len(train_labels))\n",
        "print(len(val_files))\n",
        "print(len(test_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gz-5RXBIUayh"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to match ResNet input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize grayscale images\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CustomDataset(train_files, train_labels, transform)\n",
        "val_dataset = CustomDataset(val_files, val_labels, transform)\n",
        "test_dataset = CustomDataset(test_files, test_labels, transform)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-IVjb2UUcw2",
        "outputId": "5335346a-72f1-4446-fa17-28bfda8ff543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "GPU Memory: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11aM7jsYUq7m",
        "outputId": "339eab2d-fea0-44c6-d4b0-b88a05109392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Version: 12.4\n",
            "PyTorch Version: 2.5.1+cu124\n",
            "Available GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "print(\"CUDA Version:\", torch.version.cuda)\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"Available GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mek19m_UtQ3",
        "outputId": "7f26e253-1788-45b9-d85e-340fa948cf60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 141MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = 2  # Binary classification\n",
        "model = CBAMClassifier(num_classes=num_classes, pretrained=True).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn46m432U9Gn"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eorHUzEU7gD"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\")):\n",
        "            try:\n",
        "                # Move data to device\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Clear gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Calculate statistics\n",
        "                running_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "                if (batch_idx + 1) % 10 == 0:\n",
        "                    print(f\"  Batch {batch_idx + 1}/{len(train_loader)}: \"\n",
        "                          f\"Loss = {loss.item():.4f}, \"\n",
        "                          f\"Accuracy = {correct/total:.4f}\")\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
        "                torch.cuda.empty_cache()  # Clear CUDA memory\n",
        "                continue\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = correct / total\n",
        "        train_loss.append(epoch_loss)\n",
        "        train_acc.append(epoch_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} completed. Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': epoch_loss,\n",
        "            }\n",
        "            torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "\n",
        "    return train_loss, val_loss, train_acc, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "e7zDfB_iYBW6"
      },
      "outputs": [],
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sArZrpsiXAu7",
        "outputId": "e6d4d319-1fa9-4e19-af67-78a405642f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Starting training...\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:   8%|▊         | 10/121 [22:30<4:05:30, 132.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.3136, Accuracy = 0.7352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  17%|█▋        | 20/121 [43:32<3:29:04, 124.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.3001, Accuracy = 0.7984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  25%|██▍       | 30/121 [1:03:54<3:05:38, 122.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.2291, Accuracy = 0.8250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  33%|███▎      | 40/121 [1:23:50<2:41:03, 119.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.2494, Accuracy = 0.8432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  41%|████▏     | 50/121 [1:43:22<2:21:10, 119.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.1864, Accuracy = 0.8531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  50%|████▉     | 60/121 [2:02:29<1:56:48, 114.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.2552, Accuracy = 0.8586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  58%|█████▊    | 70/121 [2:21:55<1:39:19, 116.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.2167, Accuracy = 0.8646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  66%|██████▌   | 80/121 [2:41:40<1:20:03, 117.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.2014, Accuracy = 0.8688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  74%|███████▍  | 90/121 [3:00:59<59:32, 115.23s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.2735, Accuracy = 0.8737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  83%|████████▎ | 100/121 [3:20:25<40:15, 115.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.2108, Accuracy = 0.8767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  91%|█████████ | 110/121 [3:39:31<21:02, 114.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.2433, Accuracy = 0.8795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:  99%|█████████▉| 120/121 [3:58:10<01:52, 112.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.2481, Accuracy = 0.8822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1: 100%|██████████| 121/121 [3:59:46<00:00, 118.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 completed. Loss: 0.2752, Accuracy: 0.8827\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:   8%|▊         | 10/121 [00:12<02:15,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.2260, Accuracy = 0.9195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  17%|█▋        | 20/121 [00:24<02:02,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.1706, Accuracy = 0.9176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  25%|██▍       | 30/121 [00:36<01:51,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.2168, Accuracy = 0.9164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  33%|███▎      | 40/121 [00:48<01:39,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.2179, Accuracy = 0.9160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  41%|████▏     | 50/121 [01:01<01:26,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.2120, Accuracy = 0.9152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  50%|████▉     | 60/121 [01:13<01:14,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.2398, Accuracy = 0.9164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  58%|█████▊    | 70/121 [01:25<01:02,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.1458, Accuracy = 0.9192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  66%|██████▌   | 80/121 [01:37<00:49,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.1900, Accuracy = 0.9204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  74%|███████▍  | 90/121 [01:49<00:37,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.2029, Accuracy = 0.9208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  83%|████████▎ | 100/121 [02:02<00:25,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.1901, Accuracy = 0.9209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  91%|█████████ | 110/121 [02:14<00:13,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.1750, Accuracy = 0.9208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2:  99%|█████████▉| 120/121 [02:26<00:01,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.1758, Accuracy = 0.9215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2: 100%|██████████| 121/121 [02:27<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 completed. Loss: 0.2005, Accuracy: 0.9217\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:   8%|▊         | 10/121 [00:12<02:16,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.3269, Accuracy = 0.9336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  17%|█▋        | 20/121 [00:24<02:03,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.1748, Accuracy = 0.9328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  25%|██▍       | 30/121 [00:36<01:51,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.1622, Accuracy = 0.9341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  33%|███▎      | 40/121 [00:48<01:38,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.1531, Accuracy = 0.9371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  41%|████▏     | 50/121 [01:00<01:27,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.1305, Accuracy = 0.9375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  50%|████▉     | 60/121 [01:13<01:14,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.1762, Accuracy = 0.9361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  58%|█████▊    | 70/121 [01:25<01:02,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.1778, Accuracy = 0.9347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  66%|██████▌   | 80/121 [01:37<00:51,  1.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.1450, Accuracy = 0.9329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  74%|███████▍  | 90/121 [01:50<00:39,  1.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.1336, Accuracy = 0.9341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  83%|████████▎ | 100/121 [02:02<00:25,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.1435, Accuracy = 0.9353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  91%|█████████ | 110/121 [02:14<00:13,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.1314, Accuracy = 0.9359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3:  99%|█████████▉| 120/121 [02:26<00:01,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.2247, Accuracy = 0.9354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3: 100%|██████████| 121/121 [02:27<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 completed. Loss: 0.1740, Accuracy: 0.9356\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:   8%|▊         | 10/121 [00:12<02:18,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.1823, Accuracy = 0.9570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  17%|█▋        | 20/121 [00:24<02:04,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.1014, Accuracy = 0.9496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  25%|██▍       | 30/121 [00:36<01:52,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.1327, Accuracy = 0.9458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  33%|███▎      | 40/121 [00:49<01:39,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.1651, Accuracy = 0.9447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  41%|████▏     | 50/121 [01:01<01:26,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.0659, Accuracy = 0.9461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  50%|████▉     | 60/121 [01:13<01:15,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.1403, Accuracy = 0.9458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  58%|█████▊    | 70/121 [01:25<01:02,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.1325, Accuracy = 0.9460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  66%|██████▌   | 80/121 [01:38<00:50,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.1875, Accuracy = 0.9463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  74%|███████▍  | 90/121 [01:50<00:38,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.1450, Accuracy = 0.9467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  83%|████████▎ | 100/121 [02:02<00:25,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.1195, Accuracy = 0.9470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  91%|█████████ | 110/121 [02:14<00:13,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.1717, Accuracy = 0.9464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4:  99%|█████████▉| 120/121 [02:26<00:01,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.2170, Accuracy = 0.9452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4: 100%|██████████| 121/121 [02:27<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 completed. Loss: 0.1482, Accuracy: 0.9450\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:   8%|▊         | 10/121 [00:12<02:17,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.1588, Accuracy = 0.9539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  17%|█▋        | 20/121 [00:24<02:05,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.0989, Accuracy = 0.9527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  25%|██▍       | 30/121 [00:36<01:50,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.1605, Accuracy = 0.9513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  33%|███▎      | 40/121 [00:48<01:38,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.1757, Accuracy = 0.9525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  41%|████▏     | 50/121 [01:00<01:25,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.1556, Accuracy = 0.9519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  50%|████▉     | 60/121 [01:13<01:14,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.1230, Accuracy = 0.9527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  58%|█████▊    | 70/121 [01:25<01:01,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.0966, Accuracy = 0.9522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  66%|██████▌   | 80/121 [01:37<00:49,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.1293, Accuracy = 0.9524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  74%|███████▍  | 90/121 [01:49<00:37,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.1484, Accuracy = 0.9518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  83%|████████▎ | 100/121 [02:02<00:25,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.0984, Accuracy = 0.9517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  91%|█████████ | 110/121 [02:14<00:13,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.1074, Accuracy = 0.9526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5:  99%|█████████▉| 120/121 [02:26<00:01,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.1082, Accuracy = 0.9524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5: 100%|██████████| 121/121 [02:27<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 completed. Loss: 0.1302, Accuracy: 0.9527\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:   8%|▊         | 10/121 [00:13<02:18,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.1020, Accuracy = 0.9531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  17%|█▋        | 20/121 [00:25<02:03,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.1445, Accuracy = 0.9492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  25%|██▍       | 30/121 [00:37<01:49,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.1376, Accuracy = 0.9503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  33%|███▎      | 40/121 [00:49<01:38,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.1213, Accuracy = 0.9508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  41%|████▏     | 50/121 [01:01<01:25,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.0797, Accuracy = 0.9527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  50%|████▉     | 60/121 [01:13<01:15,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.1039, Accuracy = 0.9548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  58%|█████▊    | 70/121 [01:26<01:02,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.2018, Accuracy = 0.9560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  66%|██████▌   | 80/121 [01:38<00:49,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.2275, Accuracy = 0.9554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  74%|███████▍  | 90/121 [01:50<00:37,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.0684, Accuracy = 0.9552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  83%|████████▎ | 100/121 [02:02<00:25,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.1227, Accuracy = 0.9557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  91%|█████████ | 110/121 [02:14<00:13,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.1193, Accuracy = 0.9559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6:  99%|█████████▉| 120/121 [02:26<00:01,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.1335, Accuracy = 0.9554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6: 100%|██████████| 121/121 [02:27<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 completed. Loss: 0.1152, Accuracy: 0.9556\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:   8%|▊         | 10/121 [00:12<02:14,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.1020, Accuracy = 0.9523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  17%|█▋        | 20/121 [00:24<02:03,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.0732, Accuracy = 0.9598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  25%|██▍       | 30/121 [00:36<01:50,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.1369, Accuracy = 0.9596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  33%|███▎      | 40/121 [00:48<01:39,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.0990, Accuracy = 0.9611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  41%|████▏     | 50/121 [01:00<01:27,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.1077, Accuracy = 0.9608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  50%|████▉     | 60/121 [01:13<01:14,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.1653, Accuracy = 0.9596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  58%|█████▊    | 70/121 [01:25<01:02,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.1263, Accuracy = 0.9588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  66%|██████▌   | 80/121 [01:37<00:50,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.0660, Accuracy = 0.9589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  74%|███████▍  | 90/121 [01:49<00:38,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.0604, Accuracy = 0.9602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  83%|████████▎ | 100/121 [02:02<00:26,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.1174, Accuracy = 0.9605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  91%|█████████ | 110/121 [02:14<00:13,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.0731, Accuracy = 0.9611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7:  99%|█████████▉| 120/121 [02:26<00:01,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.0895, Accuracy = 0.9617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7: 100%|██████████| 121/121 [02:27<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 completed. Loss: 0.1030, Accuracy: 0.9618\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:   8%|▊         | 10/121 [00:12<02:15,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.0917, Accuracy = 0.9648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  17%|█▋        | 20/121 [00:24<02:04,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.1587, Accuracy = 0.9613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  25%|██▍       | 30/121 [00:36<01:50,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.0839, Accuracy = 0.9617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  33%|███▎      | 40/121 [00:48<01:38,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.1008, Accuracy = 0.9641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  41%|████▏     | 50/121 [01:00<01:26,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.0606, Accuracy = 0.9642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  50%|████▉     | 60/121 [01:13<01:15,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.0587, Accuracy = 0.9646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  58%|█████▊    | 70/121 [01:25<01:02,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.1114, Accuracy = 0.9647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  66%|██████▌   | 80/121 [01:37<00:50,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.0278, Accuracy = 0.9661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  74%|███████▍  | 90/121 [01:49<00:37,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.1502, Accuracy = 0.9652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  83%|████████▎ | 100/121 [02:01<00:25,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.0988, Accuracy = 0.9642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  91%|█████████ | 110/121 [02:14<00:13,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.0742, Accuracy = 0.9634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8:  99%|█████████▉| 120/121 [02:26<00:01,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.1178, Accuracy = 0.9622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8: 100%|██████████| 121/121 [02:27<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 completed. Loss: 0.0990, Accuracy: 0.9624\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:   8%|▊         | 10/121 [00:12<02:14,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.0960, Accuracy = 0.9602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  17%|█▋        | 20/121 [00:24<02:02,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.0371, Accuracy = 0.9633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  25%|██▍       | 30/121 [00:36<01:50,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.0449, Accuracy = 0.9654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  33%|███▎      | 40/121 [00:48<01:39,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.1367, Accuracy = 0.9680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  41%|████▏     | 50/121 [01:00<01:25,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.0704, Accuracy = 0.9689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  50%|████▉     | 60/121 [01:12<01:14,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.1099, Accuracy = 0.9686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  58%|█████▊    | 70/121 [01:24<01:02,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.0806, Accuracy = 0.9691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  66%|██████▌   | 80/121 [01:36<00:49,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.0727, Accuracy = 0.9693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  74%|███████▍  | 90/121 [01:49<00:37,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.0405, Accuracy = 0.9689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  83%|████████▎ | 100/121 [02:01<00:25,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.0711, Accuracy = 0.9685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  91%|█████████ | 110/121 [02:13<00:13,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.0983, Accuracy = 0.9679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9:  99%|█████████▉| 120/121 [02:25<00:01,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.0560, Accuracy = 0.9684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9: 100%|██████████| 121/121 [02:26<00:00,  1.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 completed. Loss: 0.0856, Accuracy: 0.9683\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:   8%|▊         | 10/121 [00:12<02:15,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 10/121: Loss = 0.0440, Accuracy = 0.9719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  17%|█▋        | 20/121 [00:24<02:02,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 20/121: Loss = 0.0874, Accuracy = 0.9703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  25%|██▍       | 30/121 [00:36<01:49,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 30/121: Loss = 0.1225, Accuracy = 0.9674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  33%|███▎      | 40/121 [00:48<01:38,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 40/121: Loss = 0.1064, Accuracy = 0.9662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  41%|████▏     | 50/121 [01:00<01:26,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 50/121: Loss = 0.0857, Accuracy = 0.9658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  50%|████▉     | 60/121 [01:13<01:13,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 60/121: Loss = 0.0642, Accuracy = 0.9668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  58%|█████▊    | 70/121 [01:25<01:01,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 70/121: Loss = 0.1449, Accuracy = 0.9662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  66%|██████▌   | 80/121 [01:37<00:49,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 80/121: Loss = 0.0761, Accuracy = 0.9672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  74%|███████▍  | 90/121 [01:49<00:37,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 90/121: Loss = 0.0888, Accuracy = 0.9679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  83%|████████▎ | 100/121 [02:01<00:25,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 100/121: Loss = 0.0667, Accuracy = 0.9677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  91%|█████████ | 110/121 [02:13<00:13,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 110/121: Loss = 0.0951, Accuracy = 0.9678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10:  99%|█████████▉| 120/121 [02:25<00:01,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 120/121: Loss = 0.0799, Accuracy = 0.9680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10: 100%|██████████| 121/121 [02:26<00:00,  1.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 completed. Loss: 0.0819, Accuracy: 0.9680\n"
          ]
        }
      ],
      "source": [
        "train_loss, val_loss, train_acc, val_acc = train_model(model=model,\n",
        "  train_loader=train_loader,\n",
        "  val_loader=val_loader,\n",
        "  criterion=criterion,\n",
        "  optimizer=optimizer,\n",
        "  num_epochs=10,\n",
        "  device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ktYu_W4B746Y"
      },
      "outputs": [],
      "source": [
        "model_path = \"/content/drive/MyDrive/research_project/trained_model.pth\"  # Adjust for PyTorch\n",
        "torch.save(model.state_dict(), model_path)  # For PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading model"
      ],
      "metadata": {
        "id": "i8JWX_HZ7dzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the model (same as before)\n",
        "num_classes = 2\n",
        "model = CBAMClassifier(num_classes=num_classes, pretrained=True).to(device)\n",
        "\n",
        "# Load the saved model weights\n",
        "model_path = \"/content/drive/MyDrive/research_project/trained_model.pth\"\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ Model loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0exJ5Bs37dK9",
        "outputId": "e805afa7-b547-402b-e644-1c9fb4cb8988"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-1d805ed9a3b3>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "atuDAANSPF__"
      },
      "outputs": [],
      "source": [
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validate_model(model, val_loader, criterion, device, best_val_acc, save_path):\n",
        "    print(\"\\nStarting validation...\")\n",
        "\n",
        "    # Switch to evaluation mode\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(tqdm(val_loader, desc=\"Validating\")):\n",
        "            try:\n",
        "                # Move data to device\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Calculate statistics\n",
        "                running_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "                if (batch_idx + 1) % 10 == 0:\n",
        "                    print(f\"  Batch {batch_idx + 1}/{len(val_loader)}: \"\n",
        "                          f\"Loss = {loss.item():.4f}, \"\n",
        "                          f\"Accuracy = {correct / total:.4f}\")\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "\n",
        "    # Calculate overall validation loss and accuracy\n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    print(f\"\\nValidation completed. Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "    # Save the best validated model\n",
        "    if epoch_acc > best_val_acc:\n",
        "        best_val_acc = epoch_acc\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"✅ New best model saved with accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "    return epoch_loss, epoch_acc, best_val_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB2xUlm273Ec",
        "outputId": "5a2f9632-384d-48f5-f76a-7bf9896ba93d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating:  24%|██▍       | 10/41 [27:22<1:24:43, 163.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 10/41: Loss = 0.1679, Accuracy = 0.9539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating:  49%|████▉     | 20/41 [53:21<53:57, 154.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 20/41: Loss = 0.1990, Accuracy = 0.9500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating:  73%|███████▎  | 30/41 [1:18:37<27:31, 150.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 30/41: Loss = 0.1682, Accuracy = 0.9531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating:  98%|█████████▊| 40/41 [1:43:10<02:28, 148.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 40/41: Loss = 0.0311, Accuracy = 0.9563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 41/41 [1:43:46<00:00, 151.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation completed. Loss: 0.1274, Accuracy: 0.9565\n",
            "✅ New best model saved with accuracy: 0.9565\n",
            "Validation history saved at: /content/drive/MyDrive/research_project/val_history.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "# Initialize best validation accuracy\n",
        "best_val_acc = 0.0\n",
        "\n",
        "# Path to save the validated model\n",
        "validated_model_path = \"/content/drive/MyDrive/research_project/validated_model.pth\"\n",
        "\n",
        "# Run validation and save best model\n",
        "val_epoch_loss, val_epoch_acc, best_val_acc = validate_model(model, val_loader, criterion, device, best_val_acc, validated_model_path)\n",
        "\n",
        "# Append results to lists\n",
        "val_loss.append(val_epoch_loss)\n",
        "val_acc.append(val_epoch_acc)\n",
        "\n",
        "# ✅ Save validation loss & accuracy to a checkpoint for later use\n",
        "history_path = \"/content/drive/MyDrive/research_project/val_history.pkl\"\n",
        "history = {\"val_loss\": val_loss, \"val_acc\": val_acc}\n",
        "\n",
        "with open(history_path, \"wb\") as f:\n",
        "    pickle.dump(history, f)\n",
        "\n",
        "print(f\"Validation history saved at: {history_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/research_project/validated_model.pth\"\n",
        "\n",
        "# Load the trained model\n",
        "model = CBAMClassifier(num_classes=2, pretrained=False).to(device)  # Ensure same architecture\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()  # Set to evaluation mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z1p2i4tUV9L0",
        "outputId": "bfe86509-89e8-4552-8f30-5296d1e6aaee"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-518787e67640>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBAMClassifier(\n",
              "  (feature_extractor): ResNetFeatureExtractor(\n",
              "    (resnet): ResNet(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "    )\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (7): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cbam): CBAM(\n",
              "    (channel_attention): ChannelAttention(\n",
              "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
              "      (fc): Sequential(\n",
              "        (0): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (spatial_attention): SpatialAttention(\n",
              "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "  )\n",
              "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    test_loss = running_loss / len(test_loader)\n",
        "    test_accuracy = correct / total\n",
        "\n",
        "    print(f\"✅ Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "# Run testing\n",
        "test_loss, test_accuracy = test_model(model, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "v5q47zNqVnU8",
        "outputId": "00e335fc-2921-4d20-b42a-e7251dc5abf3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:   0%|          | 0/41 [00:21<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a6f9492b2d59>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Run testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-a6f9492b2d59>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No need to track gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Testing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d50a945fe6d1>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Open the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Apply transformations if provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mdeprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"transparency\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_loss, test_accuracy = test_model(model, test_loader, device)"
      ],
      "metadata": {
        "id": "t-rC0QwgWXny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tested_model_path = \"/content/drive/MyDrive/research_project/tested_model.pth\"\n",
        "torch.save(model.state_dict(), tested_model_path)\n",
        "print(f\"Tested model saved at: {tested_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0hCulLuWy9F",
        "outputId": "e9ad6522-9acb-4d2b-d56e-56a1c549ecb3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tested model saved at: /content/drive/MyDrive/research_project/tested_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting loss and acc values thru saved checkpoint"
      ],
      "metadata": {
        "id": "u9qR54tN1UYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/research_project/checkpoint_epoch_10.pth\"  # Update with your latest checkpoint\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "# Extract loss and accuracy if available\n",
        "train_loss = checkpoint.get('loss', [])\n",
        "print(\"Loaded train loss from checkpoint:\", train_loss)\n",
        "train_acc = checkpoint.get('acc', [])\n",
        "print(\"Loaded train accuracy from checkpoint:\", train_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA9hnx_kT62V",
        "outputId": "ccbf8dd3-fb49-4790-c73d-30f3a4da4bd0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-e8aac429b7ae>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded train loss from checkpoint: 0.08188448764753244\n",
            "Loaded train accuracy from checkpoint: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"train_loss: \", train_loss)\n",
        "print(f\"val_loss: \", val_loss)\n",
        "\n",
        "# Ensure train_loss is a list\n",
        "if isinstance(train_loss, float):\n",
        "    train_loss = [train_loss]\n",
        "\n",
        "# Ensure val_loss is a list (just a safety check)\n",
        "if isinstance(val_loss, float):\n",
        "    val_loss = [val_loss]\n",
        "\n",
        "print(\"Processed train_loss:\", train_loss)\n",
        "print(\"Processed val_loss:\", val_loss)\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)  # Create epoch numbers\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_loss, label='Training Loss', marker='o')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss', marker='s')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training & Validation Loss Curves')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "'''\n",
        "# Plot training & validation accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_acc, label=\"Training Accuracy\")\n",
        "plt.plot(val_acc, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training & Validation Accuracy Curve\")\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "lmMDTj0wWz61",
        "outputId": "96ac43a5-6532-4b18-9d81-5578966d792f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss:  [0.08188448764753244]\n",
            "val_loss:  [0.12740879051569032]\n",
            "Processed train_loss: [0.08188448764753244]\n",
            "Processed val_loss: [0.12740879051569032]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Plot training & validation accuracy\\nplt.figure(figsize=(10, 5))\\nplt.plot(train_acc, label=\"Training Accuracy\")\\nplt.plot(val_acc, label=\"Validation Accuracy\")\\nplt.xlabel(\"Epochs\")\\nplt.ylabel(\"Accuracy\")\\nplt.legend()\\nplt.title(\"Training & Validation Accuracy Curve\")\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}